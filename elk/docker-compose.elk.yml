version: '3.5'
# This compose file stands up Scrapy Cluster with an
# associated ELK Stack. You should run a few crawls and then import the
# `export.json` file into your Kibana objects

services:
  kafka_monitor:
    image: istresearch/scrapy-cluster:kafka-monitor-dev
    volumes:
      - logs:/usr/src/app/logs
    environment:
      - LOG_STDOUT=False
      - LOG_JSON=True
    depends_on:
      - kafka
      - redis
    restart: always
  redis_monitor:
    image: istresearch/scrapy-cluster:redis-monitor-dev
    volumes:
      - logs:/usr/src/app/logs
    environment:
      - LOG_STDOUT=False
      - LOG_JSON=True
    depends_on:
      - kafka
      - redis
      - zookeeper
    restart: always
  crawler:
    image: istresearch/scrapy-cluster:crawler-dev
    volumes:
      - logs:/usr/src/app/logs
    environment:
      - SC_LOG_STDOUT=False
      - SC_LOG_JSON=True
    depends_on:
      - kafka
      - redis
      - zookeeper
    restart: always
  rest:
    image: istresearch/scrapy-cluster:rest-dev
    volumes:
      - logs:/usr/src/app/logs
    depends_on:
      - kafka
      - redis
    restart: always
    ports:
      - "5343:5343"
    environment:
      - LOG_STDOUT=False
      - LOG_JSON=True
  redis:
    image: redis
    ports:
      - "6379"
    restart: always
    # command: redis-server --requirepass redispassword
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    restart: always
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ADVERTISED_HOST_NAME: kafka
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
    restart: always

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.2
    volumes:
      - type: bind
        source: ./elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      # - type: volume
      #   source: elasticsearch
      #   target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      discovery.type: single-node
      #bootstrap.memory_lock: true
    restart: always

  kibana:
    image: docker.elastic.co/kibana/kibana-oss:7.10.2
    volumes:
      - type: bind
        source: ./kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    restart: always

  filebeat:
    image: docker.elastic.co/beats/filebeat-oss:7.10.2
    command: filebeat -e -strict.perms=false
    volumes:
      - logs:/usr/share/filebeat/logs/scrapy-cluster
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
    depends_on:
      - elasticsearch
      - kibana
    restart: always

volumes:
  logs:
  # elasticsearch:
